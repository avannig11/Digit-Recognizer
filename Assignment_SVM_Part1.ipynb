{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       int64\n",
       "pixel0      int64\n",
       "pixel1      int64\n",
       "pixel2      int64\n",
       "pixel3      int64\n",
       "pixel4      int64\n",
       "pixel5      int64\n",
       "pixel6      int64\n",
       "pixel7      int64\n",
       "pixel8      int64\n",
       "pixel9      int64\n",
       "pixel10     int64\n",
       "pixel11     int64\n",
       "pixel12     int64\n",
       "pixel13     int64\n",
       "pixel14     int64\n",
       "pixel15     int64\n",
       "pixel16     int64\n",
       "pixel17     int64\n",
       "pixel18     int64\n",
       "pixel19     int64\n",
       "pixel20     int64\n",
       "pixel21     int64\n",
       "pixel22     int64\n",
       "pixel23     int64\n",
       "pixel24     int64\n",
       "pixel25     int64\n",
       "pixel26     int64\n",
       "pixel27     int64\n",
       "pixel28     int64\n",
       "            ...  \n",
       "pixel754    int64\n",
       "pixel755    int64\n",
       "pixel756    int64\n",
       "pixel757    int64\n",
       "pixel758    int64\n",
       "pixel759    int64\n",
       "pixel760    int64\n",
       "pixel761    int64\n",
       "pixel762    int64\n",
       "pixel763    int64\n",
       "pixel764    int64\n",
       "pixel765    int64\n",
       "pixel766    int64\n",
       "pixel767    int64\n",
       "pixel768    int64\n",
       "pixel769    int64\n",
       "pixel770    int64\n",
       "pixel771    int64\n",
       "pixel772    int64\n",
       "pixel773    int64\n",
       "pixel774    int64\n",
       "pixel775    int64\n",
       "pixel776    int64\n",
       "pixel777    int64\n",
       "pixel778    int64\n",
       "pixel779    int64\n",
       "pixel780    int64\n",
       "pixel781    int64\n",
       "pixel782    int64\n",
       "pixel783    int64\n",
       "Length: 785, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0.0\n",
       "pixel0      0.0\n",
       "pixel1      0.0\n",
       "pixel2      0.0\n",
       "pixel3      0.0\n",
       "pixel4      0.0\n",
       "pixel5      0.0\n",
       "pixel6      0.0\n",
       "pixel7      0.0\n",
       "pixel8      0.0\n",
       "pixel9      0.0\n",
       "pixel10     0.0\n",
       "pixel11     0.0\n",
       "pixel12     0.0\n",
       "pixel13     0.0\n",
       "pixel14     0.0\n",
       "pixel15     0.0\n",
       "pixel16     0.0\n",
       "pixel17     0.0\n",
       "pixel18     0.0\n",
       "pixel19     0.0\n",
       "pixel20     0.0\n",
       "pixel21     0.0\n",
       "pixel22     0.0\n",
       "pixel23     0.0\n",
       "pixel24     0.0\n",
       "pixel25     0.0\n",
       "pixel26     0.0\n",
       "pixel27     0.0\n",
       "pixel28     0.0\n",
       "           ... \n",
       "pixel754    0.0\n",
       "pixel755    0.0\n",
       "pixel756    0.0\n",
       "pixel757    0.0\n",
       "pixel758    0.0\n",
       "pixel759    0.0\n",
       "pixel760    0.0\n",
       "pixel761    0.0\n",
       "pixel762    0.0\n",
       "pixel763    0.0\n",
       "pixel764    0.0\n",
       "pixel765    0.0\n",
       "pixel766    0.0\n",
       "pixel767    0.0\n",
       "pixel768    0.0\n",
       "pixel769    0.0\n",
       "pixel770    0.0\n",
       "pixel771    0.0\n",
       "pixel772    0.0\n",
       "pixel773    0.0\n",
       "pixel774    0.0\n",
       "pixel775    0.0\n",
       "pixel776    0.0\n",
       "pixel777    0.0\n",
       "pixel778    0.0\n",
       "pixel779    0.0\n",
       "pixel780    0.0\n",
       "pixel781    0.0\n",
       "pixel782    0.0\n",
       "pixel783    0.0\n",
       "Length: 785, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.isnull().sum()/len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10%        1.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "20%        1.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "30%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "40%        3.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "60%        5.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "70%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "80%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "90%        8.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "95%        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "96%        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "97%        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "98%        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "99%        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "100%       9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8    ...         pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0    ...     42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0    ...         0.219286      0.117095   \n",
       "std        0.0      0.0      0.0    ...         6.312890      4.633819   \n",
       "min        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "10%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "20%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "30%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "40%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "60%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "70%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "80%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "90%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "95%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "96%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "97%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "98%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "99%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "100%       0.0      0.0      0.0    ...       254.000000    254.000000   \n",
       "max        0.0      0.0      0.0    ...       254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "10%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "20%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "30%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "40%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "60%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "70%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "80%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "90%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "95%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "96%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "97%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "98%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "99%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "100%     253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "10%         0.0       0.0       0.0  \n",
       "20%         0.0       0.0       0.0  \n",
       "30%         0.0       0.0       0.0  \n",
       "40%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "60%         0.0       0.0       0.0  \n",
       "70%         0.0       0.0       0.0  \n",
       "80%         0.0       0.0       0.0  \n",
       "90%         0.0       0.0       0.0  \n",
       "95%         0.0       0.0       0.0  \n",
       "96%         0.0       0.0       0.0  \n",
       "97%         0.0       0.0       0.0  \n",
       "98%         0.0       0.0       0.0  \n",
       "99%         0.0       0.0       0.0  \n",
       "100%        0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[20 rows x 785 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(percentiles=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.96,0.97,0.98,0.99,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data , Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and y\n",
    "X = df.drop(\"label\", axis = 1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling data\n",
    "X_scaled = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.8, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "\n",
    "model_linear = SVC(kernel='linear')\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model_linear.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.913125 \n",
      "\n",
      "[[3188    0   10    5   11   20   32    3   15    1]\n",
      " [   0 3677   14   11    5    7    4    8   30    4]\n",
      " [  36   29 3027   54   55   10   30   42   48   12]\n",
      " [  13   12  104 3051    9  181    5   21   54   25]\n",
      " [   8   14   33    2 3057    4   25   31    6  110]\n",
      " [  30   23   29  136   44 2622   44   12   72   27]\n",
      " [  26   11   44    4   28   33 3113    0   18    0]\n",
      " [   7   24   36   19   59    9    2 3210    4  134]\n",
      " [  13   46   50  120   21  110   30   18 2843   21]\n",
      " [  19   17   21   22  172   20    4  161   26 2893]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and accuracy\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3285\n",
      "           1       0.95      0.98      0.97      3760\n",
      "           2       0.90      0.91      0.90      3343\n",
      "           3       0.89      0.88      0.88      3475\n",
      "           4       0.88      0.93      0.91      3290\n",
      "           5       0.87      0.86      0.87      3039\n",
      "           6       0.95      0.95      0.95      3277\n",
      "           7       0.92      0.92      0.92      3504\n",
      "           8       0.91      0.87      0.89      3272\n",
      "           9       0.90      0.86      0.88      3355\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     33600\n",
      "   macro avg       0.91      0.91      0.91     33600\n",
      "weighted avg       0.91      0.91      0.91     33600\n",
      "\n",
      "Precision Score ::  0.913125 \n",
      "\n",
      "Recall Score ::  0.913125 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing the classification matrix\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking the precison and recall values\n",
    "print(\"Precision Score :: \",metrics.precision_score(y_test,y_pred,pos_label='positive',average='micro'),\"\\n\")\n",
    "\n",
    "print(\"Recall Score :: \",metrics.recall_score(y_test,y_pred,pos_label='positive',average='micro'),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The linear model gives approximately 91% accuracy. Let's look at a sufficiently non-linear model with randomly chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-linear model\n",
    "# using rbf kernel, C=1, default value of gamma\n",
    "\n",
    "# model\n",
    "non_linear_model = SVC(kernel='rbf')\n",
    "\n",
    "# fit\n",
    "non_linear_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = non_linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9396428571428571 \n",
      "\n",
      "[[3195    0   19    5    4   11   32    4   14    1]\n",
      " [   0 3689   23   12    8    3    7    6    8    4]\n",
      " [  15   15 3144   29   31    5   18   37   43    6]\n",
      " [   5    8   92 3191    5   73    6   31   43   21]\n",
      " [   3    7   57    1 3099    9   19   21    7   67]\n",
      " [  15   10   37   66   16 2776   53   15   32   19]\n",
      " [  19    5   46    1   12   31 3149    2   12    0]\n",
      " [   6   21   66   11   25    3    0 3285    3   84]\n",
      " [  14   24   40   63   14   62   22   19 2996   18]\n",
      " [  12   10   38   40   80    6    0   97   24 3048]]\n",
      "Precision Score ::  0.9396428571428571 \n",
      "\n",
      "Recall Score ::  0.9396428571428571 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3285\n",
      "           1       0.97      0.98      0.98      3760\n",
      "           2       0.88      0.94      0.91      3343\n",
      "           3       0.93      0.92      0.93      3475\n",
      "           4       0.94      0.94      0.94      3290\n",
      "           5       0.93      0.91      0.92      3039\n",
      "           6       0.95      0.96      0.96      3277\n",
      "           7       0.93      0.94      0.94      3504\n",
      "           8       0.94      0.92      0.93      3272\n",
      "           9       0.93      0.91      0.92      3355\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     33600\n",
      "   macro avg       0.94      0.94      0.94     33600\n",
      "weighted avg       0.94      0.94      0.94     33600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the below values for the non-linear model\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "#Checking the precison and recall values\n",
    "print(\"Precision Score :: \",metrics.precision_score(y_test,y_pred,pos_label='positive',average='micro'),\"\\n\")\n",
    "\n",
    "print(\"Recall Score :: \",metrics.recall_score(y_test,y_pred,pos_label='positive',average='micro'),\"\\n\")\n",
    "\n",
    "#printing the classification matrix\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search : Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 58.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=101, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 101)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "# specify model\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.318706</td>\n",
       "      <td>0.812199</td>\n",
       "      <td>8.049869</td>\n",
       "      <td>0.022764</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.750595</td>\n",
       "      <td>0.747024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.010784</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.565594</td>\n",
       "      <td>0.069744</td>\n",
       "      <td>4.670120</td>\n",
       "      <td>0.026190</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.935119</td>\n",
       "      <td>0.926786</td>\n",
       "      <td>0.935119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930833</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>4</td>\n",
       "      <td>0.972321</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.972173</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.972113</td>\n",
       "      <td>0.000663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.891277</td>\n",
       "      <td>0.186519</td>\n",
       "      <td>6.420241</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.910119</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.907738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903095</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>8</td>\n",
       "      <td>0.916518</td>\n",
       "      <td>0.917708</td>\n",
       "      <td>0.916518</td>\n",
       "      <td>0.921577</td>\n",
       "      <td>0.919940</td>\n",
       "      <td>0.918452</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.160887</td>\n",
       "      <td>0.857915</td>\n",
       "      <td>8.127872</td>\n",
       "      <td>0.087999</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.766071</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.765476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760476</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.223699</td>\n",
       "      <td>0.137531</td>\n",
       "      <td>4.169251</td>\n",
       "      <td>0.035730</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.941071</td>\n",
       "      <td>0.938690</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939405</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999554</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999345</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.611133</td>\n",
       "      <td>0.321545</td>\n",
       "      <td>3.964249</td>\n",
       "      <td>0.066417</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.933929</td>\n",
       "      <td>0.923214</td>\n",
       "      <td>0.931548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927262</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>5</td>\n",
       "      <td>0.957887</td>\n",
       "      <td>0.959970</td>\n",
       "      <td>0.959375</td>\n",
       "      <td>0.957738</td>\n",
       "      <td>0.959077</td>\n",
       "      <td>0.958810</td>\n",
       "      <td>0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65.337072</td>\n",
       "      <td>0.537602</td>\n",
       "      <td>8.169241</td>\n",
       "      <td>0.200885</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.766071</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.765476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760476</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.702650</td>\n",
       "      <td>0.322796</td>\n",
       "      <td>4.262039</td>\n",
       "      <td>0.062399</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.939881</td>\n",
       "      <td>0.936905</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.788407</td>\n",
       "      <td>0.095587</td>\n",
       "      <td>3.234755</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.929762</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>6</td>\n",
       "      <td>0.994345</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>0.994940</td>\n",
       "      <td>0.993006</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66.232389</td>\n",
       "      <td>0.381996</td>\n",
       "      <td>8.196086</td>\n",
       "      <td>0.034068</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01}</td>\n",
       "      <td>0.766071</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.765476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760476</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.834461</td>\n",
       "      <td>0.209680</td>\n",
       "      <td>4.356061</td>\n",
       "      <td>0.137198</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001}</td>\n",
       "      <td>0.939881</td>\n",
       "      <td>0.936905</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.747156</td>\n",
       "      <td>0.111169</td>\n",
       "      <td>3.228173</td>\n",
       "      <td>0.059195</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001}</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.920238</td>\n",
       "      <td>0.924405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920357</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       62.318706      0.812199         8.049869        0.022764       1   \n",
       "1       15.565594      0.069744         4.670120        0.026190       1   \n",
       "2       22.891277      0.186519         6.420241        0.144385       1   \n",
       "3       65.160887      0.857915         8.127872        0.087999      10   \n",
       "4       13.223699      0.137531         4.169251        0.035730      10   \n",
       "5       10.611133      0.321545         3.964249        0.066417      10   \n",
       "6       65.337072      0.537602         8.169241        0.200885     100   \n",
       "7       13.702650      0.322796         4.262039        0.062399     100   \n",
       "8        7.788407      0.095587         3.234755        0.031465     100   \n",
       "9       66.232389      0.381996         8.196086        0.034068    1000   \n",
       "10      13.834461      0.209680         4.356061        0.137198    1000   \n",
       "11       7.747156      0.111169         3.228173        0.059195    1000   \n",
       "\n",
       "   param_gamma                        params  split0_test_score  \\\n",
       "0         0.01       {'C': 1, 'gamma': 0.01}           0.752381   \n",
       "1        0.001      {'C': 1, 'gamma': 0.001}           0.935119   \n",
       "2       0.0001     {'C': 1, 'gamma': 0.0001}           0.910119   \n",
       "3         0.01      {'C': 10, 'gamma': 0.01}           0.766071   \n",
       "4        0.001     {'C': 10, 'gamma': 0.001}           0.941071   \n",
       "5       0.0001    {'C': 10, 'gamma': 0.0001}           0.933929   \n",
       "6         0.01     {'C': 100, 'gamma': 0.01}           0.766071   \n",
       "7        0.001    {'C': 100, 'gamma': 0.001}           0.939881   \n",
       "8       0.0001   {'C': 100, 'gamma': 0.0001}           0.929762   \n",
       "9         0.01    {'C': 1000, 'gamma': 0.01}           0.766071   \n",
       "10       0.001   {'C': 1000, 'gamma': 0.001}           0.939881   \n",
       "11      0.0001  {'C': 1000, 'gamma': 0.0001}           0.921429   \n",
       "\n",
       "    split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "0            0.750595           0.747024       ...                0.741310   \n",
       "1            0.926786           0.935119       ...                0.930833   \n",
       "2            0.905952           0.907738       ...                0.903095   \n",
       "3            0.772619           0.765476       ...                0.760476   \n",
       "4            0.938690           0.945833       ...                0.939405   \n",
       "5            0.923214           0.931548       ...                0.927262   \n",
       "6            0.772619           0.765476       ...                0.760476   \n",
       "7            0.936905           0.946429       ...                0.939286   \n",
       "8            0.923810           0.925595       ...                0.925595   \n",
       "9            0.772619           0.765476       ...                0.760476   \n",
       "10           0.936905           0.946429       ...                0.939286   \n",
       "11           0.920238           0.924405       ...                0.920357   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.010784               12            1.000000            0.999851   \n",
       "1         0.004216                4            0.972321            0.971429   \n",
       "2         0.006075                8            0.916518            0.917708   \n",
       "3         0.009705                9            1.000000            1.000000   \n",
       "4         0.003865                1            0.999405            0.999554   \n",
       "5         0.004678                5            0.957887            0.959970   \n",
       "6         0.009705                9            1.000000            1.000000   \n",
       "7         0.003783                2            1.000000            1.000000   \n",
       "8         0.003409                6            0.994345            0.994494   \n",
       "9         0.009705                9            1.000000            1.000000   \n",
       "10        0.003783                2            1.000000            1.000000   \n",
       "11        0.002877                7            1.000000            1.000000   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.999851            1.000000            1.000000   \n",
       "1             0.971429            0.972173            0.973214   \n",
       "2             0.916518            0.921577            0.919940   \n",
       "3             1.000000            1.000000            1.000000   \n",
       "4             0.999405            0.999107            0.999256   \n",
       "5             0.959375            0.957738            0.959077   \n",
       "6             1.000000            1.000000            1.000000   \n",
       "7             1.000000            1.000000            1.000000   \n",
       "8             0.994940            0.993006            0.994196   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "11            1.000000            1.000000            1.000000   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.999940         0.000073  \n",
       "1           0.972113         0.000663  \n",
       "2           0.918452         0.002001  \n",
       "3           1.000000         0.000000  \n",
       "4           0.999345         0.000152  \n",
       "5           0.958810         0.000865  \n",
       "6           1.000000         0.000000  \n",
       "7           1.000000         0.000000  \n",
       "8           0.994196         0.000645  \n",
       "9           1.000000         0.000000  \n",
       "10          1.000000         0.000000  \n",
       "11          1.000000         0.000000  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above show some useful insights:\n",
    "\n",
    "Non-linear models perform  better than the linear model.\n",
    "At any value of gamma, a high value of C leads to better performance None of the models tend to overfit (even the complex ones), since the training and test accuracies closely follow each other This suggests that the problem and the data is inherently non-linear in nature, and a complex model will outperform simple, linear models in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.9394047619047619 corresponding to hyperparameters {'C': 10, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#Choosing the best hyperparameters\n",
    "# printing the optimal accuracy score and hyperparameters\n",
    "best_score = model_cv.best_score_\n",
    "best_hyperparams = model_cv.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9477083333333334 \n",
      "\n",
      "Precision Score ::  0.9477083333333334\n",
      "Recall Score ::  0.9477083333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3285\n",
      "           1       0.98      0.98      0.98      3760\n",
      "           2       0.90      0.95      0.92      3343\n",
      "           3       0.95      0.93      0.94      3475\n",
      "           4       0.94      0.95      0.94      3290\n",
      "           5       0.94      0.93      0.93      3039\n",
      "           6       0.96      0.97      0.96      3277\n",
      "           7       0.94      0.95      0.94      3504\n",
      "           8       0.96      0.93      0.94      3272\n",
      "           9       0.95      0.92      0.93      3355\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     33600\n",
      "   macro avg       0.95      0.95      0.95     33600\n",
      "weighted avg       0.95      0.95      0.95     33600\n",
      "\n",
      "[[3211    0   19    2    2   12   26    3    8    2]\n",
      " [   0 3692   26    9    6    3    5    9    7    3]\n",
      " [  13   12 3165   29   29    6   20   40   21    8]\n",
      " [   4    5   77 3232    4   79    1   23   31   19]\n",
      " [   5    8   42    1 3117    5   20   19    9   64]\n",
      " [  15    8   33   61   15 2815   35   11   31   15]\n",
      " [  19    5   44    1   12   18 3167    1   10    0]\n",
      " [   5   17   52   12   29    4    1 3322    4   58]\n",
      " [   7   16   42   53   15   51   18   16 3044   10]\n",
      " [   9    9   33   20   81   10    0   94   21 3078]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model with optimal hyperparameters\n",
    "\n",
    "# model\n",
    "model = SVC(C=10, gamma=0.001, kernel=\"rbf\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# metrics\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred), \"\\n\")\n",
    "\n",
    "print(\"Precision Score :: \",metrics.precision_score(y_test,y_pred,pos_label='positive',average='micro'))\n",
    "\n",
    "print(\"Recall Score :: \",metrics.recall_score(y_test,y_pred,pos_label='positive',average='micro'))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The accuracy achieved using a non-linear kernel (0.947) is higher than that of a linear one (0.91). We can conclude that the problem is highly non-linear in nature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
